{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime('%H%M_%m%d%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14317013328114034532\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11131259456\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3781685903256362717\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed value for all of frameworks\n",
    "seed_value= 2021 \n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Call Loss Functions\n",
    "from loss_functions import dice_coef_loss\n",
    "# Call Data Generator\n",
    "from data_generator import data_generator\n",
    "# Call U-Net Model\n",
    "from unet_models import unetModel_basic_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "# dataFolder = '/sbgenomics/project-files/DATASET_BUD/'\n",
    "# EPOCH = 1\n",
    "# BS = 16\n",
    "# model_no = 1\n",
    "# cuda_no = 0\n",
    "# model_name = 'test'\n",
    "# size_img = 512\n",
    "# scale_factor = 1\n",
    "\n",
    "parameters_dict = {\n",
    "    \"data_folder\": '/sbgenomics/project-files/DATASET_BUD/',\n",
    "    \"batch_size\": 16,\n",
    "    \"epoch\": 100,\n",
    "    \"model_no\": 1,\n",
    "    \"gpu_no\": '0',\n",
    "    \"model_name\": 'test',\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"size_img\": 512,\n",
    "    \"scale_factor\": 1\n",
    "}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = parameters_dict['gpu_no']\n",
    "\n",
    "# Set Main Parameters\n",
    "IMG_WIDTH = parameters_dict['size_img']\n",
    "IMG_HEIGHT = parameters_dict['size_img']\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = parameters_dict['data_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Directory\n",
    "dir_write = 'OUTPUT/RUN_TRAIN/' + '' + '/Run_Train_' + 'test' + '_' + str(current_time) + '/'\n",
    "dir_pred = dir_write + 'Pred_imgs/'\n",
    "dir_model = dir_write + 'Model/'\n",
    "dir_log = dir_write + 'Log/'\n",
    "if not os.path.exists(dir_write):\n",
    "    os.makedirs(dir_write)\n",
    "    os.makedirs(dir_pred)\n",
    "    os.makedirs(dir_model)\n",
    "    os.makedirs(dir_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_size-16_epoch-100_model_no-1_cuda_no-0_model_name-test_learning_rate-0.001_size_img-512_scale_factor-1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naming_parameter = '_'.join(list([key + \"-\" + str(val) for key,val in parameters_dict.items()])[1:]) \n",
    "parameters_dict['model_name'] = naming_parameter\n",
    "naming_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write hyperparameters to txt file\n",
    "\n",
    "fname_hyper = dir_write + 'parameters_' + parameters_dict['model_name'] + '_' + str(current_time) + '.txt'\n",
    "str_info = 'dataset: ' + parameters_dict['data_folder'] + '\\n' + 'EPOCH: ' + str(parameters_dict['epoch']) +'\\n' + \\\n",
    "            'BS: ' + str(parameters_dict['batch_size']) + '\\n' + 'model no: ' + str(parameters_dict['model_no']) + '\\n' + \\\n",
    "            'model name: ' + parameters_dict['model_name'] + '\\n' + 'size of img: ' + str(parameters_dict['size_img']) + '\\n' + \\\n",
    "            'weight scale: ' + str(parameters_dict['scale_factor'])\n",
    "file_info = open(fname_hyper, 'w')\n",
    "file_info.write(str_info)\n",
    "file_info.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Getting and resizing(512x512) train images and masks before ... \n",
      "[DEBUG] Getting and Resizing Train Images and Masks after... \n",
      "Path to img: /sbgenomics/project-files/DATASET_BUD/img/\n",
      "# of Samples Image: 254\t# of samples mask: 254\n",
      "[DEBUG][INFO] Data Matrix: 780.288 mb\n"
     ]
    }
   ],
   "source": [
    "print(f'[DEBUG] Getting and resizing({IMG_WIDTH}x{IMG_HEIGHT}) train images and masks before ... ')\n",
    "\n",
    "# Get and resize train images and masks\n",
    "train_cpt = int(sum([len(files) for r, d, files in os.walk(TRAIN_PATH + \"img/\")]))\n",
    "\n",
    "X_train = np.ndarray((train_cpt, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
    "Y_train = np.ndarray((train_cpt, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)  # dtype=np.bool)\n",
    "\n",
    "print(f'[DEBUG] Getting and Resizing Train Images and Masks after... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "path = TRAIN_PATH + \"img/\"\n",
    "pathMask = TRAIN_PATH + \"mask/\"\n",
    "print('Path to img: {}'.format(path))\n",
    "\n",
    "_, _, filesInPath = next(os.walk(path))\n",
    "_, _, filesInPathMask = next(os.walk(pathMask))\n",
    "\n",
    "print(f'# of Samples Image: {len(filesInPath)}\\t# of samples mask: {len(filesInPathMask)}')\n",
    "\n",
    "filesInPath = sorted(filesInPath)\n",
    "filesInPathMask = sorted(filesInPathMask)\n",
    "\n",
    "for i, f in enumerate(filesInPath):\n",
    "    img = cv2.imread(path + f)\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_AREA)\n",
    "    img = img / 255\n",
    "    X_train[i] = img\n",
    "\n",
    "for i, fm in enumerate(filesInPathMask):\n",
    "    img_mask = cv2.imread(pathMask + fm, cv2.IMREAD_GRAYSCALE)\n",
    "    img_mask = cv2.resize(img_mask, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_AREA)\n",
    "    img_mask = img_mask / 255\n",
    "    img_mask = np.expand_dims(img_mask, axis=-1)\n",
    "    Y_train[i] = img_mask\n",
    "\n",
    "print(f\"[DEBUG][INFO] Data Matrix: {round(X_train.nbytes / (1024 * 1000.0),3)} mb\")\n",
    "###########################\n",
    "pixels = Y_train.flatten().reshape(train_cpt, IMG_HEIGHT*IMG_WIDTH)\n",
    "\n",
    "weights_train = pixels.copy()\n",
    "\n",
    "pixels = np.expand_dims(pixels, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unetModel_basic_4(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, lr_rate=parameters_dict['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "# print(model.summary())\n",
    "file_info = open(fname_hyper, 'a')\n",
    "model.summary(print_fn=lambda x: file_info.write('\\n' + x + '\\n'))\n",
    "file_info.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "# Stop training when a monitoring quantity has stopped improving\n",
    "# earlystopper = EarlyStopping(monitor='val_loss', patience=100, verbose=1)\n",
    "\n",
    "# Save the model after every epoch\n",
    "checkpointer = ModelCheckpoint(parameters_dict['model_name'] + '_main_modelCheckpoint.h5', verbose=0, monitor='val_loss', \\\n",
    "                               save_best_only=True, save_weights_only=False, period=1, mode='auto')\n",
    "\n",
    "name_unique_ext = parameters_dict['model_name']\n",
    "csv_logger = CSVLogger('{}/log_{}.training.csv'.format(dir_log, name_unique_ext))\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=10, verbose=1, mode='max', cooldown=1, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model fitting...\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 20s 1s/step - loss: 0.9734 - dice_coef: 0.0268 - val_loss: 0.9065 - val_dice_coef: 0.1190\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.9303 - dice_coef: 0.0697 - val_loss: 0.8963 - val_dice_coef: 0.1204\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.9250 - dice_coef: 0.0749 - val_loss: 0.8857 - val_dice_coef: 0.1398\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.9168 - dice_coef: 0.0831 - val_loss: 0.8439 - val_dice_coef: 0.1800\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.9013 - dice_coef: 0.0987 - val_loss: 0.7841 - val_dice_coef: 0.2434\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.8396 - dice_coef: 0.1610 - val_loss: 0.8074 - val_dice_coef: 0.2447\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7804 - dice_coef: 0.2200 - val_loss: 0.7057 - val_dice_coef: 0.3446\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7420 - dice_coef: 0.2587 - val_loss: 0.6440 - val_dice_coef: 0.3926\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7068 - dice_coef: 0.2928 - val_loss: 0.8008 - val_dice_coef: 0.2478\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7481 - dice_coef: 0.2520 - val_loss: 0.7344 - val_dice_coef: 0.3170\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7322 - dice_coef: 0.2682 - val_loss: 0.6325 - val_dice_coef: 0.4054\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7094 - dice_coef: 0.2908 - val_loss: 0.7248 - val_dice_coef: 0.3262\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.7413 - dice_coef: 0.2595 - val_loss: 0.6018 - val_dice_coef: 0.4303\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6767 - dice_coef: 0.3232 - val_loss: 0.5726 - val_dice_coef: 0.4449\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6399 - dice_coef: 0.3609 - val_loss: 0.6165 - val_dice_coef: 0.4220\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6082 - dice_coef: 0.3923 - val_loss: 0.5655 - val_dice_coef: 0.4634\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6201 - dice_coef: 0.3798 - val_loss: 0.6545 - val_dice_coef: 0.3918\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6203 - dice_coef: 0.3791 - val_loss: 0.5894 - val_dice_coef: 0.4262\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6177 - dice_coef: 0.3819 - val_loss: 0.5856 - val_dice_coef: 0.4397\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6891 - dice_coef: 0.3112 - val_loss: 0.5477 - val_dice_coef: 0.4724\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6059 - dice_coef: 0.3944 - val_loss: 0.5986 - val_dice_coef: 0.4344\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6452 - dice_coef: 0.3544 - val_loss: 0.6276 - val_dice_coef: 0.4132\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6040 - dice_coef: 0.3965 - val_loss: 0.6024 - val_dice_coef: 0.4077\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6631 - dice_coef: 0.3372 - val_loss: 0.5966 - val_dice_coef: 0.4281\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6193 - dice_coef: 0.3811 - val_loss: 0.5323 - val_dice_coef: 0.4816\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6114 - dice_coef: 0.3885 - val_loss: 0.6409 - val_dice_coef: 0.4072\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6526 - dice_coef: 0.3466 - val_loss: 0.5392 - val_dice_coef: 0.4713\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5993 - dice_coef: 0.4003 - val_loss: 0.5323 - val_dice_coef: 0.4780\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5411 - dice_coef: 0.4583 - val_loss: 0.5536 - val_dice_coef: 0.4595\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5616 - dice_coef: 0.4383 - val_loss: 0.5573 - val_dice_coef: 0.4717\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6146 - dice_coef: 0.3848 - val_loss: 0.5778 - val_dice_coef: 0.4501\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5618 - dice_coef: 0.4381 - val_loss: 0.5483 - val_dice_coef: 0.4670\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5630 - dice_coef: 0.4371 - val_loss: 0.6497 - val_dice_coef: 0.3950\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6689 - dice_coef: 0.3303 - val_loss: 0.5499 - val_dice_coef: 0.4679\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6004 - dice_coef: 0.4002 - val_loss: 0.5485 - val_dice_coef: 0.4676\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5416 - dice_coef: 0.4582 - val_loss: 0.5284 - val_dice_coef: 0.4782\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5404 - dice_coef: 0.4590 - val_loss: 0.5405 - val_dice_coef: 0.4671\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.6161 - dice_coef: 0.3846 - val_loss: 0.5731 - val_dice_coef: 0.4345\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5153 - dice_coef: 0.4848 - val_loss: 0.5261 - val_dice_coef: 0.4823\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5244 - dice_coef: 0.4757 - val_loss: 0.5146 - val_dice_coef: 0.4983\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5199 - dice_coef: 0.4791 - val_loss: 0.5317 - val_dice_coef: 0.4804\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5201 - dice_coef: 0.4798 - val_loss: 0.6630 - val_dice_coef: 0.3503\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5707 - dice_coef: 0.4296 - val_loss: 0.5309 - val_dice_coef: 0.4770\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4965 - dice_coef: 0.5040 - val_loss: 0.5014 - val_dice_coef: 0.5012\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5449 - dice_coef: 0.4553 - val_loss: 0.5380 - val_dice_coef: 0.4761\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4759 - dice_coef: 0.5237 - val_loss: 0.5533 - val_dice_coef: 0.4568\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5162 - dice_coef: 0.4841 - val_loss: 0.5738 - val_dice_coef: 0.4413\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4372 - dice_coef: 0.5628 - val_loss: 0.5303 - val_dice_coef: 0.4864\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5372 - dice_coef: 0.4635 - val_loss: 0.5350 - val_dice_coef: 0.4842\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4514 - dice_coef: 0.5482 - val_loss: 0.5420 - val_dice_coef: 0.4803\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.5458 - dice_coef: 0.4543 - val_loss: 0.5824 - val_dice_coef: 0.4371\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4308 - dice_coef: 0.5683 - val_loss: 0.5712 - val_dice_coef: 0.4514\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4697 - dice_coef: 0.5307 - val_loss: 0.5764 - val_dice_coef: 0.4504\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4960 - dice_coef: 0.5041 - val_loss: 0.5771 - val_dice_coef: 0.4456\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4591 - dice_coef: 0.5415 - val_loss: 0.5610 - val_dice_coef: 0.4652\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4102 - dice_coef: 0.5902 - val_loss: 0.6130 - val_dice_coef: 0.4033\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3633 - dice_coef: 0.6362 - val_loss: 0.5875 - val_dice_coef: 0.4392\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4044 - dice_coef: 0.5954 - val_loss: 0.5848 - val_dice_coef: 0.4466\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4523 - dice_coef: 0.5486 - val_loss: 0.5634 - val_dice_coef: 0.4599\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4043 - dice_coef: 0.5963 - val_loss: 0.6127 - val_dice_coef: 0.4147\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4493 - dice_coef: 0.5506 - val_loss: 0.6326 - val_dice_coef: 0.3839\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4364 - dice_coef: 0.5629 - val_loss: 0.6069 - val_dice_coef: 0.4090\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3975 - dice_coef: 0.6019 - val_loss: 0.6145 - val_dice_coef: 0.4085\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4657 - dice_coef: 0.5347 - val_loss: 0.5961 - val_dice_coef: 0.4322\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4055 - dice_coef: 0.5950 - val_loss: 0.6077 - val_dice_coef: 0.4227\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4657 - dice_coef: 0.5354 - val_loss: 0.6529 - val_dice_coef: 0.3637\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4332 - dice_coef: 0.5667 - val_loss: 0.5944 - val_dice_coef: 0.4309\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3892 - dice_coef: 0.6110 - val_loss: 0.6221 - val_dice_coef: 0.4056\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3369 - dice_coef: 0.6633 - val_loss: 0.5945 - val_dice_coef: 0.4357\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3666 - dice_coef: 0.6336 - val_loss: 0.6426 - val_dice_coef: 0.3888\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3312 - dice_coef: 0.6689 - val_loss: 0.5938 - val_dice_coef: 0.4367\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3889 - dice_coef: 0.6107 - val_loss: 0.6178 - val_dice_coef: 0.4081\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3657 - dice_coef: 0.6336 - val_loss: 0.6338 - val_dice_coef: 0.3960\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3484 - dice_coef: 0.6512 - val_loss: 0.6327 - val_dice_coef: 0.4004\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3525 - dice_coef: 0.6479 - val_loss: 0.6233 - val_dice_coef: 0.4074\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4173 - dice_coef: 0.5829 - val_loss: 0.6275 - val_dice_coef: 0.4004\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3825 - dice_coef: 0.6178 - val_loss: 0.6272 - val_dice_coef: 0.4018\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3694 - dice_coef: 0.6302 - val_loss: 0.6264 - val_dice_coef: 0.4033\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3262 - dice_coef: 0.6737 - val_loss: 0.6429 - val_dice_coef: 0.3853\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3127 - dice_coef: 0.6870 - val_loss: 0.6340 - val_dice_coef: 0.3948\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3198 - dice_coef: 0.6800 - val_loss: 0.6155 - val_dice_coef: 0.4181\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3115 - dice_coef: 0.6881 - val_loss: 0.6300 - val_dice_coef: 0.4058\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3237 - dice_coef: 0.6766 - val_loss: 0.6519 - val_dice_coef: 0.3820\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.4237 - dice_coef: 0.5767 - val_loss: 0.6306 - val_dice_coef: 0.4015\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3699 - dice_coef: 0.6306 - val_loss: 0.6418 - val_dice_coef: 0.3895\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3565 - dice_coef: 0.6438 - val_loss: 0.6335 - val_dice_coef: 0.3990\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3413 - dice_coef: 0.6584 - val_loss: 0.6393 - val_dice_coef: 0.3932\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3714 - dice_coef: 0.6296 - val_loss: 0.6377 - val_dice_coef: 0.3954\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3126 - dice_coef: 0.6871 - val_loss: 0.6327 - val_dice_coef: 0.3994\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3458 - dice_coef: 0.6534 - val_loss: 0.6366 - val_dice_coef: 0.3931\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3441 - dice_coef: 0.6558 - val_loss: 0.6183 - val_dice_coef: 0.4120\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3773 - dice_coef: 0.6229 - val_loss: 0.6251 - val_dice_coef: 0.4060\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3546 - dice_coef: 0.6461 - val_loss: 0.6358 - val_dice_coef: 0.3955\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3711 - dice_coef: 0.6290 - val_loss: 0.6429 - val_dice_coef: 0.3874\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3234 - dice_coef: 0.6751 - val_loss: 0.6352 - val_dice_coef: 0.3941\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3410 - dice_coef: 0.6594 - val_loss: 0.6392 - val_dice_coef: 0.3903\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3219 - dice_coef: 0.6781 - val_loss: 0.6348 - val_dice_coef: 0.3954\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3355 - dice_coef: 0.6639 - val_loss: 0.6397 - val_dice_coef: 0.3909\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3117 - dice_coef: 0.6883 - val_loss: 0.6343 - val_dice_coef: 0.3968\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 17s 1s/step - loss: 0.3414 - dice_coef: 0.6586 - val_loss: 0.6349 - val_dice_coef: 0.3965\n",
      "[INFO] Model fitting is done!\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "print(\"[INFO] Model fitting...\")\n",
    "results = model.fit(X_train, pixels, validation_split=0.2, batch_size=parameters_dict['batch_size'], epochs=parameters_dict['epoch'],\n",
    "                    callbacks=[checkpointer, csv_logger, reduce_lr], verbose=1, shuffle=True)#, sample_weight=weights_train)\n",
    "print(\"[INFO] Model fitting is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write model history to the file\n",
    "import pandas as pd\n",
    "pd.DataFrame(results.history).to_csv(dir_write + \"history_\" + parameters_dict['model_name'] + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: batch_size-16_epoch-100_model_no-1_cuda_no-0_model_name-test_learning_rate-0.001_size_img-512_scale_factor-1 to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open( parameters_dict['model_name'] + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights( parameters_dict['model_name'] + \".h5\")\n",
    "print(\"Saved model: {} to disk\".format(parameters_dict['model_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction....\n",
      "1/1 - 3s\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "print('Prediction....')\n",
    "preds_test = model.predict(X_train[:10], batch_size= parameters_dict['batch_size'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 262144, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Upsampling is done!(upsampled to (512, 512) from (262144, 1)\n"
     ]
    }
   ],
   "source": [
    "preds_reshaped = np.ndarray((len(preds_test), IMG_HEIGHT, IMG_WIDTH), dtype=np.float32)\n",
    "for i in range(len(preds_test)):\n",
    "    preds_reshaped[i] = preds_test[i].reshape(IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "preds_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_upsampled.append(np.expand_dims(cv2.resize(preds_reshaped[i], (IMG_HEIGHT, IMG_WIDTH)), axis=-1))\n",
    "print(\"[INFO] Upsampling is done!(upsampled to ({}, {}) from ({}, {})\".format(IMG_HEIGHT, IMG_WIDTH, preds_test[i].shape[0], preds_test[i].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED TRAINING!\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    img_mask = np.zeros((IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = preds_upsampled[k]\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            if img[i][j] > 0.25:\n",
    "                img_mask[i][j] = 1\n",
    "            else:\n",
    "                img_mask[i][j] = 0\n",
    "    img_mask *= 255\n",
    "\n",
    "    cv2.imwrite(dir_pred + filesInPath[k], img_mask)\n",
    "print('FINISHED TRAINING!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.56420190e-02, 1.04882289e-03, 8.24602757e-05, ...,\n",
       "         1.02202735e-04, 4.24940488e-04, 6.65157381e-03],\n",
       "        [1.30318440e-04, 1.07092535e-06, 8.74409452e-08, ...,\n",
       "         4.73958636e-07, 5.10872269e-06, 4.17713367e-04],\n",
       "        [2.16416229e-05, 2.05903135e-07, 3.97768041e-08, ...,\n",
       "         3.46473001e-07, 3.51130984e-06, 3.10111354e-04],\n",
       "        ...,\n",
       "        [4.03091944e-05, 9.14032299e-08, 7.50734408e-09, ...,\n",
       "         1.40608336e-09, 5.63318849e-08, 3.44579676e-05],\n",
       "        [1.60592972e-04, 1.23540588e-06, 2.05338978e-07, ...,\n",
       "         2.82650578e-08, 5.73341765e-07, 1.31053413e-04],\n",
       "        [6.55167131e-03, 2.13950363e-04, 5.08847843e-05, ...,\n",
       "         1.74235686e-06, 1.04318806e-05, 5.40183799e-04]],\n",
       "\n",
       "       [[1.03768837e-02, 5.48331591e-04, 3.83087827e-05, ...,\n",
       "         1.24171711e-04, 5.00192342e-04, 7.39447959e-03],\n",
       "        [5.53901664e-05, 4.13871817e-07, 3.65674460e-08, ...,\n",
       "         5.93760547e-07, 6.15330464e-06, 4.88606165e-04],\n",
       "        [1.17744776e-05, 1.22704762e-07, 2.85918027e-08, ...,\n",
       "         3.72461386e-07, 3.70552470e-06, 3.29158647e-04],\n",
       "        ...,\n",
       "        [4.68735598e-05, 1.06602265e-07, 8.09189871e-09, ...,\n",
       "         8.15276888e-16, 7.17280917e-14, 1.32983435e-09],\n",
       "        [1.61269694e-04, 1.26554482e-06, 1.98830520e-07, ...,\n",
       "         2.51033189e-13, 1.48793113e-11, 8.47259329e-08],\n",
       "        [6.43347716e-03, 1.94916080e-04, 4.04181992e-05, ...,\n",
       "         5.93213867e-10, 5.25057597e-09, 2.22701374e-06]],\n",
       "\n",
       "       [[7.92581472e-04, 4.29588272e-06, 5.03929130e-08, ...,\n",
       "         9.66033476e-05, 4.07143059e-04, 6.51232013e-03],\n",
       "        [9.09285234e-08, 5.67500864e-12, 4.07612244e-14, ...,\n",
       "         4.85157102e-07, 5.13568784e-06, 4.29312204e-04],\n",
       "        [1.97741890e-09, 9.54722887e-14, 1.01093118e-15, ...,\n",
       "         3.64158609e-07, 3.64514767e-06, 3.22194974e-04],\n",
       "        ...,\n",
       "        [1.59814117e-05, 2.52571208e-08, 1.92009275e-09, ...,\n",
       "         4.16459185e-12, 1.06023787e-10, 1.82351556e-07],\n",
       "        [7.89511105e-05, 4.50377911e-07, 6.62623449e-08, ...,\n",
       "         3.22449067e-10, 5.51471269e-09, 3.83580800e-06],\n",
       "        [4.31560399e-03, 1.00911268e-04, 1.94721633e-05, ...,\n",
       "         1.00445988e-07, 3.99504330e-07, 3.81601967e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.08435731e-02, 5.45355608e-04, 3.53297946e-05, ...,\n",
       "         2.92704055e-11, 2.33702790e-09, 3.07493269e-06],\n",
       "        [6.43285020e-05, 4.61582317e-07, 3.66387276e-08, ...,\n",
       "         1.35429724e-17, 3.00205519e-14, 2.55982946e-09],\n",
       "        [1.44138385e-05, 1.48458312e-07, 3.39423352e-08, ...,\n",
       "         2.13722442e-19, 1.22974890e-15, 2.55097221e-10],\n",
       "        ...,\n",
       "        [5.50968398e-05, 2.23608723e-07, 3.01587271e-08, ...,\n",
       "         1.79451298e-08, 1.05928926e-07, 1.41446808e-05],\n",
       "        [2.31569822e-04, 2.56327121e-06, 5.76918467e-07, ...,\n",
       "         8.04917647e-07, 4.11501242e-06, 2.33270388e-04],\n",
       "        [8.07054527e-03, 3.21834581e-04, 9.38922603e-05, ...,\n",
       "         4.92273430e-05, 1.05295141e-04, 1.51795952e-03]],\n",
       "\n",
       "       [[1.13749206e-02, 6.57729455e-04, 4.86474528e-05, ...,\n",
       "         6.78295249e-17, 3.36331610e-14, 1.56144420e-09],\n",
       "        [6.11403084e-05, 4.36386415e-07, 3.90266521e-08, ...,\n",
       "         1.02645306e-27, 9.66899617e-23, 7.43193992e-15],\n",
       "        [1.00656544e-05, 8.84387603e-08, 1.89356602e-08, ...,\n",
       "         7.34901906e-32, 3.63379501e-26, 3.18345025e-17],\n",
       "        ...,\n",
       "        [2.71109229e-06, 1.22695520e-09, 6.41901393e-11, ...,\n",
       "         3.96525029e-05, 1.08978871e-04, 1.83463539e-03],\n",
       "        [2.35988409e-05, 4.37445564e-08, 4.61103822e-09, ...,\n",
       "         2.16165092e-04, 5.11496502e-04, 6.06685737e-03],\n",
       "        [2.52818526e-03, 3.47145069e-05, 6.24263248e-06, ...,\n",
       "         1.79401482e-03, 2.57590553e-03, 1.45004429e-02]],\n",
       "\n",
       "       [[7.87977036e-03, 3.15810932e-04, 1.63542481e-05, ...,\n",
       "         9.84300261e-14, 1.18107815e-11, 7.10778565e-08],\n",
       "        [3.32129930e-05, 1.68608551e-07, 1.04371782e-08, ...,\n",
       "         1.41019956e-22, 1.14118933e-18, 3.24271317e-12],\n",
       "        [6.83114513e-06, 5.00594304e-08, 9.04438213e-09, ...,\n",
       "         1.67661230e-26, 1.28290028e-21, 3.95421848e-14],\n",
       "        ...,\n",
       "        [4.62610442e-05, 1.28690772e-07, 1.22142891e-08, ...,\n",
       "         1.68194597e-10, 8.28592572e-09, 1.01823516e-05],\n",
       "        [2.18809408e-04, 1.88599131e-06, 3.24160055e-07, ...,\n",
       "         4.43105241e-09, 1.02630878e-07, 4.54456058e-05],\n",
       "        [8.04180279e-03, 2.85348127e-04, 6.95699928e-05, ...,\n",
       "         4.12264569e-07, 2.16030799e-06, 1.85818339e-04]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bud",
   "language": "python",
   "name": "env_bud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
